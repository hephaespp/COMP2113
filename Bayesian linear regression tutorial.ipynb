{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Linear Regression tutorial from https://zjost.github.io/bayesian-linear-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import normal, uniform\n",
    "from scipy.stats import multivariate_normal as mv_norm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_function(a_0, a_1, noise_sigma, x):\n",
    "    \"\"\"\n",
    "    Evaluates the real function\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    if noise_sigma==0:\n",
    "        # Recovers the true function\n",
    "        return a_0 + a_1*x\n",
    "    else:\n",
    "        return a_0 + a_1*x + normal(0, noise_sigma, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real function parameters\n",
    "a_0 = -0.3\n",
    "a_1 = 0.5\n",
    "noise_sigma = 0.2\n",
    "beta = 1/noise_sigma**2\n",
    "# Generate input features from uniform distribution\n",
    "np.random.seed(20) # Set the seed so we can get reproducible results\n",
    "x_real = uniform(-1, 1, 1000)\n",
    "# Evaluate the real function for training example inputs\n",
    "t_real = real_function(a_0, a_1, noise_sigma, x_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBayes(object):\n",
    "    \"\"\"\n",
    "    A class that holds parameter prior/posterior and handles \n",
    "    the hyper-parameter updates with new data\n",
    "    \n",
    "    Note:  variables starting with \"v_\" indicate Nx1 dimensional \n",
    "        column vectors, those starting with \"m_\" indicate \n",
    "        matrices, and those starting with \"a_\" indicate \n",
    "        1xN dimensional arrays.\n",
    "    \n",
    "    Args:\n",
    "        a_m0 (np.array): prior mean vector of size 1xM\n",
    "        m_S0 (np.ndarray): prior covariance matrix of size MxM\n",
    "        beta (float): known real-data noise precision\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, a_m0, m_S0, beta):\n",
    "        self.prior = mv_norm(mean=a_m0, cov=m_S0)\n",
    "        self.v_m0 = a_m0.reshape(a_m0.shape + (1,)) #reshape to column vector\n",
    "        self.m_S0 = m_S0\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.v_mN = self.v_m0\n",
    "        self.m_SN = self.m_S0\n",
    "        self.posterior = self.prior\n",
    "           \n",
    "    def get_phi(self, a_x):\n",
    "        \"\"\"\n",
    "        Returns the design matrix of size (NxM) for a feature vector v_x.\n",
    "        In this case, this function merely adds the phi_0 dummy basis\n",
    "        that's equal to 1 for all elements.\n",
    "        \n",
    "        Args:\n",
    "            a_x (np.array): input features of size 1xN\n",
    "        \"\"\"\n",
    "        m_phi = np.ones((len(a_x), 2))\n",
    "        m_phi[:, 1] = a_x\n",
    "        return m_phi\n",
    "        \n",
    "    def set_posterior(self, a_x, a_t):\n",
    "        \"\"\"\n",
    "        Updates mN and SN given vectors of x-values and t-values\n",
    "        \"\"\"\n",
    "        # Need to convert v_t from an array into a column vector\n",
    "        # to correctly compute matrix multiplication\n",
    "        v_t = a_t.reshape(a_t.shape + (1,))\n",
    "\n",
    "        m_phi = self.get_phi(a_x)\n",
    "        \n",
    "        self.m_SN = np.linalg.inv(np.linalg.inv(self.m_S0) + self.beta*m_phi.T.dot(m_phi))\n",
    "        self.v_mN = self.m_SN.dot(np.linalg.inv(self.m_S0).dot(self.v_m0) + \\\n",
    "                                      self.beta*m_phi.T.dot(v_t))\n",
    "        \n",
    "        self.posterior = mv_norm(mean=self.v_mN.flatten(), cov=self.m_SN)\n",
    "\n",
    "    \n",
    "    def prediction_limit(self, a_x, stdevs):\n",
    "        \"\"\"\n",
    "        Calculates the limit that's \"stdevs\" standard deviations\n",
    "        away from the mean at a given value of x.\n",
    "        \n",
    "        Args:\n",
    "            a_x (np.array): x-axis values of size 1xN\n",
    "            stdevs (float): Number of standard deviations away from\n",
    "                the mean to calculate the prediction limit\n",
    "        \n",
    "        Returns:\n",
    "            np.array: the prediction limit \"stdevs\" standard deviations\n",
    "                away from the mean corresponding to x-values in \"v_x\"\n",
    "        \n",
    "        \"\"\"\n",
    "        N = len(a_x)\n",
    "        m_x = self.get_phi(a_x).T.reshape((2, 1, N))\n",
    "        \n",
    "        predictions = []\n",
    "        for idx in range(N):\n",
    "            x = m_x[:,:,idx]\n",
    "            sig_sq_x = 1/self.beta + x.T.dot(self.m_SN.dot(x))\n",
    "            mean_x = self.v_mN.T.dot(x)\n",
    "            predictions.append((mean_x+stdevs*np.sqrt(sig_sq_x)).flatten())\n",
    "        return np.concatenate(predictions)\n",
    "    \n",
    "    def generate_data(self, a_x):\n",
    "        N = len(a_x)\n",
    "        m_x = self.get_phi(a_x).T.reshape((2, 1, N))\n",
    "        \n",
    "        predictions = []\n",
    "        for idx in range(N):\n",
    "            x = m_x[:,:,idx]\n",
    "            sig_sq_x = 1/self.beta + x.T.dot(self.m_SN.dot(x))\n",
    "            mean_x = self.v_mN.T.dot(x)\n",
    "            predictions.append(normal(mean_x.flatten(), np.sqrt(sig_sq_x)))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def make_contour(self, a_x, a_y, real_parms=[], N=0):\n",
    "        \"\"\"\n",
    "        A helper function to generate contour plots of our probability distribution\n",
    "        \"\"\"\n",
    "        pos = np.empty(a_x.shape + (2,))\n",
    "        pos[:, :, 0] = a_x\n",
    "        pos[:, :, 1] = a_y\n",
    "\n",
    "        plt.contourf(a_x, a_y, self.posterior.pdf(pos), 20)\n",
    "        plt.xlabel('$w_0$', fontsize=16)\n",
    "        plt.ylabel('$w_1$', fontsize=16)\n",
    "        \n",
    "        if real_parms:\n",
    "            plt.scatter(real_parms[0], real_parms[1], marker='+', c='black', s=60)\n",
    "            \n",
    "        _ = plt.title('Distribution for Weight Parameters using %d datapoint(s)' % N, fontsize=10)\n",
    "    \n",
    "    def make_scatter(self, a_x, a_t, real_parms, samples=None, stdevs=None):\n",
    "        \"\"\"\n",
    "        A helper function to plot noisey data, the true function, \n",
    "        and optionally a set of lines specified by the nested array of\n",
    "        weights of size NxM where N is number of lines, M is 2 for \n",
    "        this simple model\n",
    "        \"\"\"\n",
    "        plt.scatter(a_x, a_t, alpha=0.5)\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('t')\n",
    "\n",
    "        plt.plot([-1, 1], real_function(real_parms[0], real_parms[1], 0, np.array([-1., 1.])), 'r')\n",
    "\n",
    "        _ = plt.title('Real Data from Noisey Linear Function')\n",
    "        \n",
    "        if samples:\n",
    "            weights = self.posterior.rvs(samples)\n",
    "            for weight in weights: \n",
    "                plt.plot([-1, 1], real_function(weight[0], weight[1], 0, np.array([-1., 1.])), 'black')\n",
    "                _ = plt.title('Lines Sampled from Posterior Distribution vs Real Line and Data')\n",
    "                \n",
    "        if stdevs:\n",
    "            a_xrange = np.linspace(-1, 1, 100)\n",
    "            y_upper = self.prediction_limit(a_xrange, stdevs)\n",
    "            y_lower = self.prediction_limit(a_xrange, -stdevs)\n",
    "            plt.plot(a_xrange, y_upper, '+', c='green', linewidth=4.0)\n",
    "            plt.plot(a_xrange, y_lower, '+', c='green', linewidth=4.0)\n",
    "            _ = plt.title('Lines Sampled from Posterior Distribution vs Real Line and Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
